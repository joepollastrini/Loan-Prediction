{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See KNN Impute Work folder for specific work through for each model.  This file contains the cleaned version to impute and clean quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import pickle\n",
    "from matplotlib.cbook import boxplot_stats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/joepollastrini/Loan-Prediction/master\"\n",
    "train_name = 'train_loan_data.csv'\n",
    "test_name = 'test_loan_data.csv'\n",
    "    \n",
    "direct = os.getcwd()\n",
    "\n",
    "loan_term_model_name = 'knn_Loan_Term.sav'\n",
    "loan_term_cols = ['IncomePerMember', 'FamilyIncome']\n",
    "\n",
    "loan_amount_model_name = 'knn_Loan_Amount.sav'\n",
    "loan_amount_cols = ['FamilyIncome', 'LTG_<15', 'LTG_15', 'LTG_1530', 'LTG_30']\n",
    "\n",
    "self_employed_model_name = 'knn_Self_Employed.sav'\n",
    "self_employed_cols = ['FamilyIncome']\n",
    "\n",
    "credit_history_model_name = 'knn_Credit_History.sav'\n",
    "credit_history_cols = ['LTG_<15', 'LTG_15', 'LTG_1530', 'LTG_30', 'LTG_>30']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_grab_online(base, name, out='output.csv'):\n",
    "    #get data from url\n",
    "    u = base + '/' + name\n",
    "    r = requests.get(u).content\n",
    "    df = pd.read_csv(u)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_impute_and_dummy(row):\n",
    "    #if unmarried and 1 dependent female, else male\n",
    "    if pd.isnull(row['Gender']):\n",
    "        if row['Married'] == 'No' and row['Dependents'] == '1':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if row['Gender'] == 'Male':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def married_impute_and_dummy(x):\n",
    "    #if female, not married, otherwise married\n",
    "    if pd.isnull(x['Married']):\n",
    "        if x['Gender'] == 'Female':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if x['Married'] == 'Yes':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependents_impute_and_ordinal(x):\n",
    "    #if married, one dependent, otherwise none\n",
    "    #convert dependents to ordinal int as well\n",
    "    if pd.isnull(x['Dependents']):\n",
    "        if x['Married_IO'] == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif x['Dependents'] == '3+':\n",
    "        return 3\n",
    "    else:\n",
    "        return int(x['Dependents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_income_dummy(x):\n",
    "    if x['Married'] == 'Yes':\n",
    "        if x['CoapplicantIncome'] > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    col_drop = []\n",
    "    col_rename = {}\n",
    "    \n",
    "    # GENDER #\n",
    "    df['Male_IO'] = df.apply(lambda x: gender_impute_and_dummy(x), axis=1)\n",
    "    col_drop.append('Gender')\n",
    "    \n",
    "    # MARRIED #\n",
    "    df['Married_IO'] = df.apply(lambda x: married_impute_and_dummy(x), axis=1)\n",
    "    col_drop.append('Married')\n",
    "    \n",
    "    # DEPENDENTS #\n",
    "    df['Dependents2'] = df.apply(lambda x: dependents_impute_and_ordinal(x), axis=1)\n",
    "    col_drop.append('Dependents')\n",
    "    col_rename['Dependents2'] = 'Dependents'\n",
    "    \n",
    "    # FAMILY SIZE #\n",
    "    df['FamilySize'] = df['Dependents2'] + df['Married_IO'] + 1\n",
    "    \n",
    "    # EDUCATION #\n",
    "    df['Education_IO'] = df['Education'].apply(lambda x: 1 if x == 'Graduate' else 0)\n",
    "    col_drop.append('Education')\n",
    "\n",
    "    # INCOME #\n",
    "    df['FamilyIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "    df['DualIncome_IO'] = df.apply(lambda x: dual_income_dummy(x), axis=1)\n",
    "    col_drop.extend(['ApplicantIncome', 'CoapplicantIncome'])\n",
    "    \n",
    "    # PROPERTY AREA #\n",
    "    df['PA_Urban'] = df['Property_Area'].apply(lambda x: 1 if x == 'Urban' else 0)\n",
    "    df['PA_Rural'] = df['Property_Area'].apply(lambda x: 1 if x == 'Rural' else 0)\n",
    "    df['PA_Semiurban'] = df['Property_Area'].apply(lambda x: 1 if x == 'Semiurban' else 0)\n",
    "    col_drop.append('Property_Area')\n",
    "    \n",
    "    # INCOME PER FAMILY MEMBER #\n",
    "    df['IncomePerMember'] = df['FamilyIncome'] / df['FamilySize']\n",
    "    \n",
    "    # LOAN STATUS #\n",
    "    try:\n",
    "        df['Loan_Status'].replace('Y', 1, inplace=True)\n",
    "        df['Loan_Status'].replace('N', 0, inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    #column cleaning\n",
    "    df.drop(columns = col_drop, inplace=True)\n",
    "    df.rename(columns=col_rename, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loan_group(x):\n",
    "    if np.isnan(x):\n",
    "        return x\n",
    "    else:\n",
    "        x = int(x)\n",
    "        if x == 360:\n",
    "            return '30'\n",
    "        elif x == 180:\n",
    "            return '15'\n",
    "        elif x < 180:\n",
    "            return '<15'\n",
    "        elif x > 180 and x < 360:\n",
    "            return '(15, 30)'\n",
    "        elif x > 360:\n",
    "            return '>30'\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(model, row, x_cols):\n",
    "    valueList = []\n",
    "    for col in x_cols:\n",
    "        value = row[col]\n",
    "        valueList.append(value)\n",
    "\n",
    "    df = pd.DataFrame([valueList])\n",
    "    \n",
    "    prediction = model.predict(df)[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loan_term(x):\n",
    "    if '<' in x:\n",
    "        return 7.5*12.0\n",
    "    elif '(' in x:\n",
    "        return 22.5*12.0\n",
    "    elif '>' in x:\n",
    "        return 480.0\n",
    "    else:\n",
    "        return float(x)*12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(df, model, cols):\n",
    "    #group loan terms, don't change nan values\n",
    "    df['LoanTermGroups'] = df['Loan_Amount_Term'].apply(lambda x: loan_group(x))\n",
    "    \n",
    "    #create predictions using model\n",
    "    df['LTA_Predict'] = df.apply(lambda x: predict_func(model, x, cols), axis=1)\n",
    "    \n",
    "    #replace missing values from loan term groups with predicted values\n",
    "    df['LoanTermGroups'].fillna(df['LTA_Predict'], inplace=True)\n",
    "    \n",
    "    #drop columns\n",
    "    df.drop(columns = ['Loan_Amount_Term', 'LTA_Predict'], inplace=True)\n",
    "    \n",
    "    #create loan amount term monthly for calculations\n",
    "    df['Loan_Amount_Term'] = df['LoanTermGroups'].apply(lambda x: new_loan_term(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean3(df, model, cols):\n",
    "    #convert loan amount to log\n",
    "    df['LoanAmountLog'] = np.log(df['LoanAmount'].astype('float64'))\n",
    "    \n",
    "    #create dummy vars for loan term group\n",
    "    df['LTG_<15'] = df['LoanTermGroups'].apply(lambda x: 1 if x == '<15' else 0)\n",
    "    df['LTG_15'] = df['LoanTermGroups'].apply(lambda x: 1 if x == '15' else 0)\n",
    "    df['LTG_1530'] = df['LoanTermGroups'].apply(lambda x: 1 if x == '(15, 30)' else 0)\n",
    "    df['LTG_30'] = df['LoanTermGroups'].apply(lambda x: 1 if x == '30' else 0)\n",
    "    df['LTG_>30'] = df['LoanTermGroups'].apply(lambda x: 1 if x == '>30' else 0)\n",
    "    \n",
    "    #predict using model\n",
    "    df['LA_Predict'] = df.apply(lambda x: predict_func(model, x, cols), axis=1)\n",
    "    \n",
    "    #replace missing values with predicted values\n",
    "    df['LoanAmountLog'].fillna(df['LA_Predict'], inplace=True)\n",
    "    \n",
    "    #drop original loan amount column and convert logged back to normal\n",
    "    df.drop(columns=['LoanAmount', 'LA_Predict'], inplace=True)\n",
    "    df['LoanAmount'] = np.exp(df['LoanAmountLog'])\n",
    "    \n",
    "    #create debt/equity variables\n",
    "    df['Debt_Equity'] = (df['LoanAmount'] * 1000) / df['FamilyIncome']\n",
    "    df['Debt_Equity_Annual'] = (((df['LoanAmount']*1000) / df['Loan_Amount_Term']) * 12) / df['FamilyIncome']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean4(df, model, cols):\n",
    "    #predict using model\n",
    "    df['SE_Predict'] = df.apply(lambda x: predict_func(model, x, cols), axis=1)\n",
    "    \n",
    "    #replace missing values with predicted values\n",
    "    df['Self_Employed'].fillna(df['SE_Predict'], inplace=True)\n",
    "    \n",
    "    #convert to dummy variable\n",
    "    df['Self_Employed_IO'] = df['Self_Employed'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "    \n",
    "    #drop original column\n",
    "    df.drop(columns=['Self_Employed', 'SE_Predict'], inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_CH(row):\n",
    "    if np.isnan(row['Credit_History']):\n",
    "        #check for no education and urban\n",
    "        if row['NoEd_Urban_IO'] == 1:\n",
    "            #use model predicted value\n",
    "            return row['CH_Predict']\n",
    "        else:\n",
    "            return 1.0\n",
    "    else:\n",
    "        return row['Credit_History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean5(df, model, cols):\n",
    "    #indicator for no education and urban property area\n",
    "    df['NoEd_Urban_IO'] = df.apply(lambda x: 1 if x['Education_IO'] == 0 and x['PA_Urban'] == 1 else 0, axis=1)\n",
    "    \n",
    "    #predict using model\n",
    "    df['CH_Predict'] = df.apply(lambda x: predict_func(model, x, cols), axis=1)\n",
    "    \n",
    "    #replace missing values with correct value\n",
    "    df['CH'] = df.apply(lambda x: fillna_CH(x), axis=1)\n",
    "    \n",
    "    #drop old column\n",
    "    df.drop(columns = ['Credit_History', 'NoEd_Urban_IO', 'CH_Predict'], inplace=True)\n",
    "    \n",
    "    #rename column\n",
    "    df.rename(columns = {'CH':'Credit_History'}, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_id(df, orig):\n",
    "    income_box = boxplot_stats(orig['FamilyIncome'])[0]\n",
    "    incLowVal = income_box['whislo']\n",
    "    incHighVal = income_box['whishi']\n",
    "    df['income_out_io'] = df['FamilyIncome'].apply(lambda x: 1 if (x < incLowVal or x > incHighVal) else 0)\n",
    "    \n",
    "    la_box = boxplot_stats(orig['LoanAmount'])[0]\n",
    "    laLowVal = la_box['whislo']\n",
    "    laHighVal = la_box['whishi']\n",
    "    df['la_out_io'] = df['LoanAmount'].apply(lambda x: 1 if (x < laLowVal or x > laHighVal) else 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_grab_online(url, train_name)\n",
    "test = data_grab_online(url, test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = clean(train)\n",
    "test_clean = clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_term_model = pickle.load(open(os.path.join(direct, 'Models', loan_term_model_name), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean2 = clean2(train_clean, loan_term_model, loan_term_cols)\n",
    "test_clean2 = clean2(test_clean, loan_term_model, loan_term_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_amount_model = pickle.load(open(os.path.join(direct, 'Models', loan_amount_model_name), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean3 = clean3(train_clean2, loan_amount_model, loan_amount_cols)\n",
    "test_clean3 = clean3(test_clean2, loan_amount_model, loan_amount_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_employed_model = pickle.load(open(os.path.join(direct, 'Models', self_employed_model_name), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean4 = clean4(train_clean3, self_employed_model, self_employed_cols)\n",
    "test_clean4 = clean4(test_clean3, self_employed_model, self_employed_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_history_model = pickle.load(open(os.path.join(direct, 'Models', credit_history_model_name), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean5 = clean5(train_clean4, credit_history_model, credit_history_cols)\n",
    "test_clean5 = clean5(test_clean4, credit_history_model, credit_history_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = train_clean5.copy()\n",
    "train_clean6 = outlier_id(train_clean5, original_train)\n",
    "test_clean6 = outlier_id(test_clean5, original_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saved clean files for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Desktop\\Project Portfolio\\Loan Prediction\n"
     ]
    }
   ],
   "source": [
    "direct = os.getcwd()\n",
    "print(direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean6.to_csv(os.path.join(direct, 'forModel_train.csv'), index=False)\n",
    "test_clean6.to_csv(os.path.join(direct, 'forModel_test.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
