{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Build\n",
    "Use KNN imputation models (forModel data sets) and then build model random forest model using cross validation and hyper param optimization.  Use the same variables as original model. (Debt/Equity, Debt/Equity per Year, Loan Amount (Logged), Education, Property Area (Semiurban), Property Area (Rural), Dependents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import roc_auc_score as ra\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import GridSearchCV as gscv\n",
    "from sklearn.model_selection import RandomizedSearchCV as rscv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/joepollastrini/Loan-Prediction/master\"\n",
    "train_name = 'forModel_train.csv'\n",
    "test_name = 'forModel_test.csv'\n",
    "response = 'Loan_Status'\n",
    "k = 10 #number of k-folds for cross validation\n",
    "n = 200 #number of iterations for randomized grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_grab_online(base, name, out='output.csv'):\n",
    "    #get data from url\n",
    "    u = base + '/' + name\n",
    "    r = requests.get(u).content\n",
    "    df = pd.read_csv(u)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(actual, pred, pos, neg):\n",
    "    #confusion matrix\n",
    "    matrix = cm(actual, pred, labels = [pos, neg])\n",
    "    tp, fn, fp, tn = matrix.ravel()\n",
    "    #matrix statistics\n",
    "    precision = tp / (tp + fp) # p(correct | predict pos)\n",
    "    recall = tp / (tp + fn) # p(correct | actual pos)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f = (2*recall*precision) / (recall + precision) # f-score\n",
    "    fpr = fp / (tn + fp) # false positive rate\n",
    "    aucroc = ra(actual, pred) # auc roc score\n",
    "    \n",
    "    print('Accuracy:\\t{:.1f}%'.format(accuracy * 100.0))\n",
    "    print('Precision:\\t{:.3f}'.format(precision))\n",
    "    print('Recall:\\t\\t{:.3f}'.format(recall))\n",
    "    print('F-Score:\\t{:.3f}'.format(f))\n",
    "    print('AUC-ROC Score:\\t{:.3f}'.format(aucroc))\n",
    "    print('FPR:\\t\\t{:.2f}%'.format(fpr * 100.0))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    print('Actual (side) vs. Predicted (top)')\n",
    "    print('\\t|  {}  \\t|  {}  \\t|'.format(pos, neg))\n",
    "    print('-------------------------')\n",
    "    print('  {}  \\t|  {} \\t|  {} \\t|'.format(pos, tp, fn))\n",
    "    print('-------------------------')\n",
    "    print('  {}  \\t|  {} \\t|  {} \\t|'.format(neg, fp, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_grab_online(url, train_name)\n",
    "test = data_grab_online(url, test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Loan_Status', 'Male_IO', 'Married_IO', 'Dependents',\n",
       "       'FamilySize', 'Education_IO', 'FamilyIncome', 'DualIncome_IO',\n",
       "       'PA_Urban', 'PA_Rural', 'PA_Semiurban', 'IncomePerMember',\n",
       "       'LoanTermGroups', 'Loan_Amount_Term', 'LoanAmountLog', 'LTG_<15',\n",
       "       'LTG_15', 'LTG_1530', 'LTG_30', 'LTG_>30', 'LoanAmount', 'Debt_Equity',\n",
       "       'Debt_Equity_Annual', 'Self_Employed_IO', 'Credit_History',\n",
       "       'income_out_io', 'la_out_io'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inlier = train.loc[(train['income_out_io'] == 0) & (train['la_out_io'] == 0)]\n",
    "test_inlier = test.loc[(test['income_out_io'] == 0) & (test['la_out_io'] == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Paramater Tune\n",
    "Start with a randomized grid to find a rough starting point.  Use the starting points to do a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid =  {'n_estimators': list(range(50, 250, 10))\n",
    "               ,'max_features': ['auto'] + list(range(3, 7, 1))\n",
    "               ,'max_depth': list(range(4, 16, 2))\n",
    "               ,'min_samples_split': [2, 5, 10, 20]\n",
    "               ,'min_samples_leaf': [1, 2, 5, 10]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Credit_History', 'Debt_Equity', 'Debt_Equity_Annual', 'LoanAmountLog', 'FamilyIncome', 'IncomePerMember']\n",
    "\n",
    "x_train = train_inlier[features]\n",
    "y_train = train_inlier[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   45.4s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 210, 'min_samples_split': 20, 'min_samples_leaf': 10, 'max_features': 5, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "model = rfc()\n",
    "tuner = rscv(estimator = model\n",
    "            ,param_distributions = random_grid\n",
    "            ,n_iter = n\n",
    "            ,cv = k\n",
    "            ,random_state = 0\n",
    "            ,verbose = 2\n",
    "            ,n_jobs = -1)\n",
    "tuner.fit(x_train, y_train)\n",
    "print(tuner.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1536 candidates, totalling 15360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 19.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9105 tasks      | elapsed: 22.9min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11697 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14613 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 15360 out of 15360 | elapsed: 40.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 195}\n"
     ]
    }
   ],
   "source": [
    "grid_search = {'n_estimators': list(range(190, 230, 5))\n",
    "               ,'max_features': list(range(4, 7, 1))\n",
    "               ,'max_depth': list(range(4, 8, 1))\n",
    "               ,'min_samples_split': list(range(16, 24, 2))\n",
    "               ,'min_samples_leaf': list(range(6, 14, 2))\n",
    "              }\n",
    "model = rfc()\n",
    "tuner = gscv(estimator = model\n",
    "            ,param_grid = grid_search\n",
    "            ,cv = k\n",
    "            ,verbose = 2\n",
    "            ,n_jobs = -1)\n",
    "tuner.fit(x_train, y_train)\n",
    "print(tuner.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=5, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=10, min_samples_split=16,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=195,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tuner.best_params_\n",
    "rf = rfc(n_estimators = d['n_estimators']\n",
    "        ,max_depth = d['max_depth']\n",
    "        ,min_samples_split = d['min_samples_split']\n",
    "        ,min_samples_leaf = d['min_samples_leaf']\n",
    "        ,max_features = d['max_features'])\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Predictions and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t83.6%\n",
      "Precision:\t0.822\n",
      "Recall:\t\t0.974\n",
      "F-Score:\t0.892\n",
      "AUC-ROC Score:\t0.750\n",
      "FPR:\t\t47.34%\n",
      "\n",
      "\n",
      "\n",
      "Actual (side) vs. Predicted (top)\n",
      "\t|  1  \t|  0  \t|\n",
      "-------------------------\n",
      "  1  \t|  370 \t|  10 \t|\n",
      "-------------------------\n",
      "  0  \t|  80 \t|  89 \t|\n"
     ]
    }
   ],
   "source": [
    "preds = rf.predict(x_train)\n",
    "score(y_train, preds, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              variable  importance\n",
      "0      Credit_History    0.677214\n",
      "1         Debt_Equity    0.129431\n",
      "2  Debt_Equity_Annual    0.068167\n",
      "5     IncomePerMember    0.058765\n",
      "4        FamilyIncome    0.038897\n",
      "3       LoanAmountLog    0.027526 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_imp = pd.concat((pd.DataFrame(x_train.columns, columns = ['variable']), \n",
    "               pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "              axis = 1).sort_values(by='importance', ascending = False)[:20]\n",
    "print('\\n', feat_imp, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = rf.predict(test[features])\n",
    "predictions = pd.DataFrame(test_preds, columns = ['Predictions'])\n",
    "test_predictions = pd.concat((test['Loan_ID'], predictions), axis=1)\n",
    "test_predictions['Loan_Status'] = test_predictions['Predictions'].apply(lambda x: 'Y' if x == 1 else 'N')\n",
    "test_predictions.drop(columns = ['Predictions'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing file to C:\\Users\\joepo\\Desktop\\Project Portfolio\\Loan Prediction\\submission.csv\n"
     ]
    }
   ],
   "source": [
    "direct = os.getcwd()\n",
    "path = os.path.join(direct, 'submission.csv')\n",
    "print('writing file to {}'.format(path))\n",
    "test_predictions.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same accuracy score of 0.7847"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
