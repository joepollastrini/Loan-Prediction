{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jpollas2/Project-Data/master\"\n",
    "train_name = 'train_loan_data.csv'\n",
    "test_name = 'test_loan_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_grab_online(base, name, out='output.csv'):\n",
    "    #get data from url\n",
    "    u = base + '/' + name\n",
    "    r = requests.get(u).content\n",
    "    df = pd.read_csv(u)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_impute_and_dummy(row):\n",
    "    #if unmarried and 1 dependent female, else male\n",
    "    if pd.isnull(row['Gender']):\n",
    "        if row['Married'] == 'No' and row['Dependents'] == '1':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if row['Gender'] == 'Male':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def married_impute_and_dummy(x):\n",
    "    #if female, not married, otherwise married\n",
    "    if pd.isnull(x['Married']):\n",
    "        if x['Male_IO'] == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if x['Married'] == 'Yes':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def dependents_impute_and_ordinal(x):\n",
    "    #if married, one dependent, otherwise none\n",
    "    #convert dependents to ordinal int as well\n",
    "    if pd.isnull(x['Dependents']):\n",
    "        if x['Married_IO'] == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    elif x['Dependents'] == '3+':\n",
    "        return 3\n",
    "    else:\n",
    "        return int(x['Dependents'])\n",
    "    \n",
    "def dual_income_dummy(x):\n",
    "    if x['Married_IO'] == 1:\n",
    "        if x['CoapplicantIncome'] > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#group loan terms\n",
    "def loan_group(x):\n",
    "    x = int(x)\n",
    "    if x == 360:\n",
    "        return '30'\n",
    "    elif x == 180:\n",
    "        return '15'\n",
    "    elif x < 180:\n",
    "        return '<15'\n",
    "    elif x > 180 and x < 360:\n",
    "        return '(15, 30)'\n",
    "    elif x > 360:\n",
    "        return '>30'\n",
    "    else:\n",
    "        return '??'\n",
    "    \n",
    "#log transform loan amount for better mean calculation later\n",
    "#group by loan term for imputation later\n",
    "def get_transform(df):\n",
    "    df['LoanAmountLog'] = np.log(df['LoanAmount'].astype('float64'))\n",
    "    group = df.groupby(['LoanTermGroups'])['LoanAmountLog']\n",
    "    return group\n",
    "\n",
    "\n",
    "def clean(df, train_orig):\n",
    "    col_drop = []\n",
    "    col_rename = {}\n",
    "    \n",
    "    # GENDER #\n",
    "    df['Male_IO'] = df.apply(lambda x: gender_impute_and_dummy(x), axis=1)\n",
    "    col_drop.append('Gender')\n",
    "    \n",
    "    # MARRIED #\n",
    "    df['Married_IO'] = df.apply(lambda x: married_impute_and_dummy(x), axis=1)\n",
    "    col_drop.append('Married')\n",
    "    \n",
    "    # DEPENDENTS #\n",
    "    df['Dependents2'] = df.apply(lambda x: dependents_impute_and_ordinal(x), axis=1)\n",
    "    col_drop.append('Dependents')\n",
    "    col_rename['Dependents2'] = 'Dependents'\n",
    "    \n",
    "    # FAMILY SIZE #\n",
    "    df['FamilySize'] = df['Dependents2'] + df['Married_IO'] + 1\n",
    "        \n",
    "    # EDUCATION #\n",
    "    df['Education_IO'] = df['Education'].apply(lambda x: 1 if x == 'Graduate' else 0)\n",
    "    col_drop.append('Education')\n",
    "    \n",
    "    # SELF EMPLOYED #\n",
    "    df['Self_Employed'].replace(np.nan, 'No', inplace=True)\n",
    "    df['Self_Employed_IO'] = df['Self_Employed'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "    col_drop.append('Self_Employed')\n",
    "\n",
    "    # INCOME #\n",
    "    df['FamilyIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
    "    df['DualIncome_IO'] = df.apply(lambda x: dual_income_dummy(x), axis=1)\n",
    "    col_drop.extend(['ApplicantIncome', 'CoapplicantIncome'])\n",
    "    \n",
    "    # LOAN TERM #\n",
    "    df['Loan_Amount_Term'].replace(np.nan, 360.0, inplace=True)\n",
    "    df['LoanTermGroups'] = df['Loan_Amount_Term'].apply(lambda x: loan_group(x))\n",
    "    \n",
    "    train_orig['Loan_Amount_Term'].replace(np.nan, 360.0, inplace=True)\n",
    "    train_orig['LoanTermGroups'] = train_orig['Loan_Amount_Term'].apply(lambda x: loan_group(x))\n",
    "    col_drop.append('LoanTermGroups')\n",
    "    \n",
    "    # LOAN AMOUNT #\n",
    "    df['LoanAmountLog'] = np.log(df['LoanAmount'].astype('float64'))\n",
    "    t = get_transform(train_orig)\n",
    "    df['LoanAmountLog'] = t.transform(lambda x: x.fillna(x.mean()))\n",
    "    df['LoanAmount2'] = np.exp(df['LoanAmountLog'])\n",
    "    col_drop.extend(['LoanAmountLog', 'LoanAmount'])\n",
    "    col_rename['LoanAmount2'] = 'LoanAmount'\n",
    "    \n",
    "    # PROPERTY AREA #\n",
    "    df['PA_Urban'] = df['Property_Area'].apply(lambda x: 1 if x == 'Urban' else 0)\n",
    "    df['PA_Rural'] = df['Property_Area'].apply(lambda x: 1 if x == 'Rural' else 0)\n",
    "    df['PA_Semiurban'] = df['Property_Area'].apply(lambda x: 1 if x == 'Semiurban' else 0)\n",
    "    col_drop.append('Property_Area')\n",
    "    \n",
    "    # DEBT/EQUITY #\n",
    "    df['LoanPerIncome'] = (df['LoanAmount2'] * 1000) / df['FamilyIncome']\n",
    "    df['Income_for_Loan_Annual'] = (((df['LoanAmount2'] * 1000) / df['Loan_Amount_Term']) * 12) / df['FamilyIncome']\n",
    "    \n",
    "    # INCOME PER FAMILY MEMBER #\n",
    "    df['IncomePerMember'] = df['FamilyIncome'] / df['FamilySize']\n",
    "    \n",
    "    #column cleaning\n",
    "    df.drop(columns = col_drop, inplace=True)\n",
    "    df.rename(columns=col_rename, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_grab_online(url, train_name)\n",
    "test = data_grab_online(url, test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "614"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = train.copy()\n",
    "train_clean = clean(train, orig)\n",
    "test_clean = clean(test, orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_forMod = train_clean.dropna()\n",
    "test_forMod = test_clean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(actual, pred, pos, neg):\n",
    "    matrix = cm(actual, pred, labels = [pos, neg])\n",
    "    tp, fn, fp, tn = matrix.ravel()\n",
    "    precision = tp / (tp + fp) # p(correct | predict pos)\n",
    "    recall = tp / (tp + fn) # p(correct | actual pos)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f = (2*recall*precision) / (recall + precision)\n",
    "    fpr = fp / (tn + fp)\n",
    "    aucroc = ra(actual, pred)\n",
    "    \n",
    "    print('Accuracy:\\t{:.1f}%'.format(accuracy * 100.0))\n",
    "    print('Precision:\\t{:.3f}'.format(precision))\n",
    "    print('Recall:\\t\\t{:.3f}'.format(recall))\n",
    "    print('F-Score:\\t{:.3f}'.format(f))\n",
    "    print('AUC-ROC Score:\\t{:.3f}'.format(aucroc))\n",
    "    print('FPR:\\t\\t{:.2f}%'.format(fpr * 100.0))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    print('Actual (side) vs. Predicted (top)')\n",
    "    print('\\t|  {}  \\t|  {}  \\t|'.format(pos, neg))\n",
    "    print('-------------------------')\n",
    "    print('  {}  \\t|  {} \\t|  {} \\t|'.format(pos, tp, fn))\n",
    "    print('-------------------------')\n",
    "    print('  {}  \\t|  {} \\t|  {} \\t|'.format(neg, fp, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import roc_auc_score as ra\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_train = train_forMod.copy()\n",
    "logReg_test = test_forMod.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = logReg_train['Credit_History']\n",
    "y_test = logReg_test['Credit_History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education_IO'], dtype='object')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = logReg_train.columns\n",
    "x_cols = cols.drop(['Loan_ID', 'Loan_Status', 'Credit_History', 'Dependents', 'PA_Semiurban', 'Self_Employed_IO'\n",
    "                   ,'LoanAmount', 'Male_IO', 'FamilySize', 'PA_Rural', 'PA_Urban', 'DualIncome_IO', 'Loan_Amount_Term'\n",
    "                   ,'Income_for_Loan_Annual', 'LoanPerIncome', 'Married_IO', 'IncomePerMember', 'FamilyIncome'])\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.432856\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:         Credit_History   No. Observations:                  564\n",
      "Model:                          Logit   Df Residuals:                      562\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Mon, 08 Jun 2020   Pseudo R-squ.:                0.007225\n",
      "Time:                        15:08:46   Log-Likelihood:                -244.13\n",
      "converged:                       True   LL-Null:                       -245.91\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.05942\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "const            1.2958      0.221      5.854      0.000       0.862       1.730\n",
      "Education_IO     0.5013      0.260      1.929      0.054      -0.008       1.010\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = sm.Logit(y_train, sm.add_constant(logReg_train[x_cols])).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t84.4%\n",
      "Precision:\t0.844\n",
      "Recall:\t\t1.000\n",
      "F-Score:\t0.915\n",
      "AUC-ROC Score:\t0.506\n",
      "FPR:\t\t98.88%\n",
      "\n",
      "\n",
      "\n",
      "Actual (side) vs. Predicted (top)\n",
      "\t|  1  \t|  0  \t|\n",
      "-------------------------\n",
      "  1  \t|  475 \t|  0 \t|\n",
      "-------------------------\n",
      "  0  \t|  88 \t|  1 \t|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogReg()\n",
    "model.fit(logReg_train[['Education_IO', 'FamilyIncome']], y_train)\n",
    "preds = model.predict(logReg_train[['Education_IO', 'FamilyIncome']])\n",
    "\n",
    "score(y_train, preds, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the exact same imputation I had.  Not worth using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train = train_forMod.copy()\n",
    "rf_test = test_forMod.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = rf_train['Credit_History']\n",
    "y_test = rf_test['Credit_History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FamilySize', 'Education_IO', 'FamilyIncome', 'LoanAmount',\n",
       "       'LoanPerIncome', 'Income_for_Loan_Annual', 'IncomePerMember'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = rf_train.columns\n",
    "x_cols = cols.drop(['Loan_ID', 'Loan_Status', 'Credit_History', 'Dependents', 'PA_Semiurban', 'Self_Employed_IO'\n",
    "                   ,'Male_IO', 'Married_IO', 'Loan_Amount_Term', 'PA_Rural', 'DualIncome_IO','PA_Urban'])\n",
    "x_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                  variable  importance\n",
      "2            FamilyIncome    0.212009\n",
      "6         IncomePerMember    0.187972\n",
      "4           LoanPerIncome    0.176010\n",
      "5  Income_for_Loan_Annual    0.158263\n",
      "3              LoanAmount    0.155034\n",
      "1            Education_IO    0.067408\n",
      "0              FamilySize    0.043304 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joepo\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = rfc(random_state=1, max_depth = 5, min_samples_split=20, min_samples_leaf=10)\n",
    "model.fit(rf_train[x_cols], y_train)\n",
    "\n",
    "features = pd.concat((pd.DataFrame(rf_train[x_cols].columns, columns = ['variable']), \n",
    "           pd.DataFrame(model.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:20]\n",
    "print('\\n', features, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\t84.2%\n",
      "Precision:\t0.842\n",
      "Recall:\t\t1.000\n",
      "F-Score:\t0.914\n",
      "AUC-ROC Score:\t0.500\n",
      "FPR:\t\t100.00%\n",
      "\n",
      "\n",
      "\n",
      "Actual (side) vs. Predicted (top)\n",
      "\t|  1  \t|  0  \t|\n",
      "-------------------------\n",
      "  1  \t|  475 \t|  0 \t|\n",
      "-------------------------\n",
      "  0  \t|  89 \t|  0 \t|\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(rf_train[x_cols])\n",
    "\n",
    "score(y_train, preds, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as my imputation again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
